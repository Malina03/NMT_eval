train-sets:
    - train_set
valid-sets:
    - dev_set 

seed: 1234
mini-batch-fit: True
workspace: 24000
shuffle-in-ram: true

early-stopping: 3
exponential-smoothing: 0.0001
keep-best: True
# Batch size is probably around 750, but can differ since we do mini-batch-fit
# So to evaluate per epoch, do data set size / 750
valid-freq: 2000
valid-mini-batch: 32
save-freq: 2000
overwrite: True
disp-freq: 2000

valid-metrics:
    - chrf
    - ce-mean-words
    - bleu-detok

beam-size: 6
normalize: 1
max-length: 200
dim-vocabs:
    - 32000

cost-type: ce-mean-words
type: transformer
enc-depth: 6
dec-depth: 6
dim-emb: 512
transformer-heads: 8
transformer-dim-ffn: 2048
transformer-ffn-depth: 2
transformer-ffn-activation: swish
transformer-decoder-autoreg: self-attention

transformer-dropout: 0.1
label-smoothing: 0.1

layer-normalization: True
tied-embeddings-all: True

learn-rate: 0.0003
lr-warmup: 16000
lr-decay-inv-sqrt: 16000
lr-report: True
optimizer-params:
    - 0.9
    - 0.98
    - 1e-09
clip-norm: 0
sync-sgd: true
optimizer-delay: 3
